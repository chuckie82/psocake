#!/usr/bin/env python
#bsub -q psanaq -a mympi -n 36 -o %J.log python generatePowder.py exp=amo87215:run=15 -d pnccdFront

from psana import *
import numpy as np
import sys

class Stats:
    def __init__(self,detarr,exp,run,detname):
        self.sum=detarr.astype(np.float64)
        self.sumsq=detarr.astype(np.float64)*detarr.astype(np.float64)
        self.maximum=detarr.astype(np.float64)
        self.nevent=1
        self.exp = exp
        self.run = run
        self.detname = detname
    def update(self,detarr):
        self.sum+=detarr
        self.sumsq+=detarr*detarr
        self.maximum=np.maximum(self.maximum,detarr)
        self.nevent+=1
    def store(self):
        self.totevent = comm.reduce(self.nevent)
        if rank==0:
            comm.Reduce(MPI.IN_PLACE,self.sum)
            comm.Reduce(MPI.IN_PLACE,self.sumsq)
            comm.Reduce(MPI.IN_PLACE,self.maximum,op=MPI.MAX)
            # Accumulating floating-point numbers introduces errors,
            # which may cause negative variances.  Since a two-pass
            # approach is unacceptable, the standard deviation is
            # clamped at zero.
            self.mean = self.sum / float(self.totevent)
            self.variance = (self.sumsq / float(self.totevent)) - (self.mean**2)
            self.variance[self.variance < 0] = 0
            self.stddev = np.sqrt(self.variance)
            file = '%s/%s_%4.4d_%s'%(args.outDir,self.exp,self.run,self.detname)
            print 'writing file',file
            #np.savez(file,mean=self.mean,stddev=self.stddev,max=self.maximum)
            np.save(file+"_mean",self.mean)
            np.save(file+"_std",self.stddev)
            np.save(file+"_max",self.maximum)
            np.save(file+"_sum",self.sum)
            # Save calibman compatible file
            calibman_max = self.maximum.reshape((-1,self.maximum.shape[-1]))
            np.savetxt(file+"_max.txt",calibman_max,fmt='%0.18e')
        else:
            comm.Reduce(self.sum,self.sum)
            comm.Reduce(self.sumsq,self.sumsq)
            comm.Reduce(self.maximum,self.maximum,op=MPI.MAX)

def getMyUnfairShare(numJobs,numWorkers,rank):
    """Returns number of events assigned to the slave calling this function."""
    assert(numJobs >= numWorkers)
    allJobs = np.arange(numJobs)
    jobChunks = np.array_split(allJobs,numWorkers)
    myChunk = jobChunks[rank]
    myJobs = allJobs[myChunk[0]:myChunk[-1]+1]
    return myJobs

def detList(s):
    try:
        return s.split(',')
    except:
        raise argparse.ArgumentTypeError("Detector list must be comma separated")

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("exprun", help="psana experiment/run string (e.g. exp=xppd7114:run=43)")
parser.add_argument('-d','--detList', help="list of detectors separated with comma (e.g. pnccdFront,pnccdBack)", dest="detList", type=detList, nargs=1)
parser.add_argument("-n","--noe",help="number of events to process",default=0, type=int)
parser.add_argument('-o','--outDir', help="output directory where .cxi will be saved (e.g. /reg/d/psdm/cxi/cxic0415/scratch)", type=str)
parser.add_argument("-t","--threshold",help="ignore ADUs below threshold",default=None, type=float)
parser.add_argument("--localCalib", help="Use local calib directory. A calib directory must exist in your current working directory.", action='store_true')
args = parser.parse_args()

print args.exprun, args.detList, args.noe, args.outDir

if args.localCalib: setOption('psana.calib-dir', './calib')

ds = DataSource(args.exprun+':idx')
env = ds.env()

# set this to sys.maxint to analyze all events
maxevents = sys.maxint

from mpi4py import MPI
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

detname = args.detList[0] #['Camp.0:pnCCD.0']#,'Camp.0:pnCCD.1']
detlist = [Detector(s, env) for s in detname]
for d,n in zip(detlist,detname):
    d.detname = n

for run in ds.runs():
    nevent = np.array([0])
    runnumber = run.run()
    # list of all events
    times = run.times()
    if args.noe == 0:
        numJobs = len(times)
    else:
        if args.noe <= len(times):
            numJobs = args.noe
        else:
            numJobs = len(times)

    ind = getMyUnfairShare(numJobs,size,rank)
    mytimes = times[ind[0]:ind[-1]+1]

    for d in detlist:
        for i,time in enumerate(mytimes):
            if i%100==0: print 'Rank',rank,'processing event', i,'of',len(mytimes)
            evt = run.event(time)
            try:
                detarr = d.calib(evt)
            except ValueError:
                id = evt.get(EventId)
                print 'Value Error!'
                print id
                print id.time(),id.fiducials()
                continue
            if detarr is None:
                print '*** failed to get detarr'
                continue
            if args.threshold is not None:
                print "Applying threshold: ", args.threshold
                detarr[detarr < args.threshold] = 0
            if not hasattr(d,'stats'):
                #print "##### init"
                d.stats = Stats(detarr,env.experiment(),evt.run(),d.detname)
            else:
                #print "##### update"
                d.stats.update(detarr)
            nevent+=1
        if hasattr(d, 'stats'):
            #print "### store"
            d.stats.store()
MPI.Finalize()
